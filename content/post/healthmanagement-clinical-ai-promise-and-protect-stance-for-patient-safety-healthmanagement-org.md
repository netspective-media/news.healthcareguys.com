---
archetype: bookmark
categories:
- ai
date: 2019-03-06T12:50:01Z
description: Health policy analysts have published a Policy Forum piece calling for
  more stringent regulations for Artificial Intelligence (AI) medical applications.
dropmark.editURL: http://radhikan.dropmark.com/616548/18146315
featuredImage: /img/content/post/healthmanagement-clinical-ai-promise-and-protect-stance-for-patient-safety-healthmanagement-org.jpg
link: https://healthmanagement.org/c/it/news/clinical-ai-promise-and-protect-stance-for-patient-safety
linkBrand: healthmanagement.org
slug: healthmanagement-clinical-ai-promise-and-protect-stance-for-patient-safety-healthmanagement-org
source:
  name: Dropmark
  apiendpoint: https://shah.dropmark.com/616548.json
title: Clinical AI “Promise and protect” stance for patient safety - HealthManagement.org
---
Health policy analysts have published a Policy Forum piece calling for more stringent regulations for Artificial Intelligence (AI) medical applications.

 

Ravi Parikh, Ziad Obermeyer and Amol Navathe, rom the University of Pennsylvania and the University of California, have suggested five standards they think should be introduced for AI medical applications.

 

They argue that as the use of medical AI and predictive analytics become more widespread in hospitals worldwide, regulations must keep pace in the interests of quality and efficiency of patient care.

 
You might also like: New IT cybersecurity rules


The researchers highlighted a concern over the lack of regulatory and clinical standards for predictive analytics following recent Food and Drug Administration (FDA) approvals for its clinical use.

 

AI and computational power have ushered in advances in use of predictive analytics in the areas of prognosis and patient outcomes. But the paper emphasised how standards and regulations over evaluation of safety and impact of AI-based algorithms are too new to be fully understood by clinicians.


The researchers expressed concern over the rigours of current regulatory processes, questioning how thorough they were.

 

In particular, they pointed out that present FDA standards do not account for the dynamic characteristics of modern algorithms including the changing predictive performance connected to data quantities.

 

The authors propose 5 standards to help evaluation and regulation of clinical predictive analytics:

 

·      Establish meaningful endpoints with benefits clearly identifiable and subject to FDA validation

·      Establish area application-appropriate benchmarks for proper usefulness and quality evaluation

·      Ensure clarity of variable input specifications for new application testing across institutions

·      Enable possible interventions related to AI systems findings with a focus on whether they are appropriate and successful.

·      Implement regular rigorous audits within the same framework to that of new

 

The authors also pointed out that, because of the novelty of AI applications and devices, the efficacy of current regulations is not yet evident. Against this background, they suggested the medical community take a stance of "promise and protection" to ensure promotion of better healthcare for patients.

